{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMTV3BzdHy18pu+RhO5RUUe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ğŸµ Internship Project â€” Task 1  \n","## **Text-to-Music Generator using Sentiment and Mood Analysis**\n","\n","### ğŸ‘¨â€ğŸ’» Submitted by:\n","**Name:** Prajwal Shinde  \n","**Internship Domain:** AI / NLP + Audio Generation  \n","**Mentor:** [Mentor292]  \n","**Submission:** Task 1 â€” Text Input & 20-Second Music Output  \n","\n","---\n","\n","### ğŸ§  **Objective**\n","The goal of this task is to develop a system that:\n","- Takes **text input** from the user  \n","- Analyzes its **sentiment** (positive, negative, or neutral)  \n","- Detects its **emotional tone/mood** (e.g., joy, sadness, anger, love, etc.)  \n","- Generates a **20-second piece of music** based on the detected mood and sentiment  \n","\n","---\n","\n","### âš™ï¸ **Process Overview**\n","1. **Input File (`input.txt`)** â€” contains user text lines.  \n","2. **Sentiment Detection** â€” using `cardiffnlp/twitter-roberta-base-sentiment-latest`.  \n","3. **Mood Detection** â€” using `bhadresh-savani/distilbert-base-uncased-emotion`.  \n","4. **Music Generation** â€” frequency-based waveform synthesis in NumPy.  \n","5. **Output Audio (`mood_sentiment_20s.wav`)** â€” 20-second unique audio clip.  \n","\n","---\n","\n","### ğŸ“‚ **Final Submission Files**\n","- ğŸ“ `input.txt` â†’ Text input file  \n","- ğŸ§ `*_20s.wav` â†’ 20-second audio file(s) generated from input  \n","\n","---\n","\n","### ğŸ’¬ **Note**\n","All code and models are run on **Google Colab** for demonstration.  \n","Music files are generated dynamically using NumPy and saved in `.wav` format.\n"],"metadata":{"id":"CiTRrRDWzTZk"}},{"cell_type":"code","source":["# âœ… STEP 1: Install dependencies\n","!pip install transformers torch numpy soundfile\n","\n","# âœ… STEP 2: Import libraries\n","from transformers import pipeline\n","import numpy as np\n","import soundfile as sf\n","\n","# âœ… STEP 3: Load your pretrained models\n","sentiment_model = pipeline(\n","    \"sentiment-analysis\",\n","    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",")\n","\n","emotion_model = pipeline(\n","    \"text-classification\",\n","    model=\"bhadresh-savani/distilbert-base-uncased-emotion\",\n","    return_all_scores=False\n",")\n","\n","# âœ… STEP 4: Create the input text file\n","with open(\"input.txt\", \"w\") as f:\n","    f.write(\"I am feeling peaceful and calm today.\\n\")\n","    f.write(\"I am very angry and frustrated right now.\\n\")\n","    f.write(\"Life feels neutral and simple today.\\n\")\n","\n","print(\"âœ… input.txt created successfully!\")\n","\n","# âœ… STEP 5: Define mood-based frequency patterns\n","mood_patterns = {\n","    'joy': ([523, 659, 784, 1046], [0.4, 0.4, 0.4, 0.4]),\n","    'anger': ([220, 220, 330, 440], [0.5, 0.5, 0.5, 0.5]),\n","    'sadness': ([220, 246, 261, 293], [0.6, 0.6, 0.6, 0.6]),\n","    'fear': ([440, 392, 349, 330], [0.5, 0.5, 0.5, 0.5]),\n","    'love': ([392, 440, 494, 523], [0.4, 0.4, 0.4, 0.4]),\n","    'surprise': ([523, 784, 988, 1319], [0.3, 0.3, 0.3, 0.3]),\n","    'neutral': ([440, 440, 440, 440], [0.5, 0.5, 0.5, 0.5])\n","}\n","\n","# âœ… STEP 6: Define music generator (20-second version)\n","def generate_music(frequencies, durations, volume=0.5, total_duration=20):\n","    sr = 22050\n","    song = np.array([], dtype=np.float32)\n","    loop_time = sum(durations)\n","    repeat_count = int(total_duration // loop_time)\n","\n","    for _ in range(repeat_count):\n","        for freq, dur in zip(frequencies, durations):\n","            freq *= np.random.uniform(0.95, 1.05)  # slight variation for realism\n","            t = np.linspace(0, dur, int(sr * dur), False)\n","            tone = volume * np.sin(2 * np.pi * freq * t)\n","            song = np.concatenate((song, tone))\n","\n","    # Fill remaining time if needed\n","    if len(song) / sr < total_duration:\n","        remaining = total_duration - (len(song) / sr)\n","        t = np.linspace(0, remaining, int(sr * remaining), False)\n","        tone = volume * np.sin(2 * np.pi * frequencies[-1] * t)\n","        song = np.concatenate((song, tone))\n","\n","    return song, sr\n","\n","# âœ… STEP 7: Process each line from input.txt and generate music\n","with open(\"input.txt\", \"r\") as f:\n","    lines = f.readlines()\n","\n","for text in lines:\n","    text = text.strip()\n","    if not text:\n","        continue\n","\n","    # Detect sentiment & mood\n","    sentiment = sentiment_model(text)[0]['label']\n","    mood = emotion_model(text)[0]['label']\n","\n","    print(f\"\\nğŸµ Text: {text}\")\n","    print(f\"ğŸ’¬ Sentiment: {sentiment}\")\n","    print(f\"ğŸ­ Mood: {mood}\")\n","\n","    # Generate and save music\n","    freqs, durs = mood_patterns.get(mood, mood_patterns['neutral'])\n","    music, sr = generate_music(freqs, durs, total_duration=20)\n","    filename = f\"{mood}_{sentiment}_20s.wav\"\n","    sf.write(filename, music, sr)\n","    print(f\"âœ… Saved 20-second audio: {filename}\")\n","\n","print(\"\\nğŸ¯ All files generated successfully! Ready for submission.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_jtPnRm10Hpl","executionInfo":{"status":"ok","timestamp":1761487152790,"user_tz":-330,"elapsed":22802,"user":{"displayName":"prajwal shinde","userId":"07316674839394468211"}},"outputId":"bc1239ac-0f87-4b57-f8fd-7e816d117483"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Device set to use cpu\n","Device set to use cpu\n"]},{"output_type":"stream","name":"stdout","text":["âœ… input.txt created successfully!\n","\n","ğŸµ Text: I am feeling peaceful and calm today.\n","ğŸ’¬ Sentiment: positive\n","ğŸ­ Mood: joy\n","âœ… Saved 20-second audio: joy_positive_20s.wav\n","\n","ğŸµ Text: I am very angry and frustrated right now.\n","ğŸ’¬ Sentiment: negative\n","ğŸ­ Mood: anger\n","âœ… Saved 20-second audio: anger_negative_20s.wav\n","\n","ğŸµ Text: Life feels neutral and simple today.\n","ğŸ’¬ Sentiment: positive\n","ğŸ­ Mood: joy\n","âœ… Saved 20-second audio: joy_positive_20s.wav\n","\n","ğŸ¯ All files generated successfully! Ready for submission.\n"]}]}]}